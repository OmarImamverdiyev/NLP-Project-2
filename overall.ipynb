{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fdcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# =====================================================\n",
    "# PATH\n",
    "# =====================================================\n",
    "\n",
    "BASE_DIR = Path(__file__).resolve().parents[1]\n",
    "CORPUS_PATH = BASE_DIR / \"Corpora\" / \"News\" / \"corpus.txt\"\n",
    "\n",
    "# =====================================================\n",
    "# READ CORPUS\n",
    "# =====================================================\n",
    "\n",
    "def load_tokens(path):\n",
    "    tokens = []\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            words = line.strip().split()\n",
    "            tokens.extend(words)\n",
    "    return tokens\n",
    "\n",
    "# =====================================================\n",
    "# SPLIT TRAIN / TEST\n",
    "# =====================================================\n",
    "\n",
    "def split_data(tokens, train_ratio=0.8):\n",
    "    split_index = int(len(tokens) * train_ratio)\n",
    "    return tokens[:split_index], tokens[split_index:]\n",
    "\n",
    "# =====================================================\n",
    "# BUILD MODELS (MLE)\n",
    "# =====================================================\n",
    "\n",
    "def build_unigram(tokens):\n",
    "    counts = Counter(tokens)\n",
    "    total = len(tokens)\n",
    "    return counts, total\n",
    "\n",
    "def build_bigram(tokens):\n",
    "    return Counter(zip(tokens[:-1], tokens[1:]))\n",
    "\n",
    "def build_trigram(tokens):\n",
    "    return Counter(zip(tokens[:-2], tokens[1:-1], tokens[2:]))\n",
    "\n",
    "# =====================================================\n",
    "# PERPLEXITY (NO SMOOTHING)\n",
    "# =====================================================\n",
    "\n",
    "def perplexity_unigram(test_tokens, counts, total):\n",
    "    log_prob = 0\n",
    "    T = len(test_tokens)\n",
    "\n",
    "    for w in test_tokens:\n",
    "        if counts[w] == 0:\n",
    "            return float(\"inf\")\n",
    "        p = counts[w] / total\n",
    "        log_prob += math.log(p)\n",
    "\n",
    "    return math.exp(-log_prob / T)\n",
    "\n",
    "def perplexity_bigram(test_tokens, bigram_counts, unigram_counts):\n",
    "    log_prob = 0\n",
    "    T = len(test_tokens) - 1\n",
    "\n",
    "    for w1, w2 in zip(test_tokens[:-1], test_tokens[1:]):\n",
    "        if bigram_counts[(w1, w2)] == 0:\n",
    "            return float(\"inf\")\n",
    "        p = bigram_counts[(w1, w2)] / unigram_counts[w1]\n",
    "        log_prob += math.log(p)\n",
    "\n",
    "    return math.exp(-log_prob / T)\n",
    "\n",
    "def perplexity_trigram(test_tokens, trigram_counts, bigram_counts):\n",
    "    log_prob = 0\n",
    "    T = len(test_tokens) - 2\n",
    "\n",
    "    for w1, w2, w3 in zip(test_tokens[:-2], test_tokens[1:-1], test_tokens[2:]):\n",
    "        if trigram_counts[(w1, w2, w3)] == 0:\n",
    "            return float(\"inf\")\n",
    "        p = trigram_counts[(w1, w2, w3)] / bigram_counts[(w1, w2)]\n",
    "        log_prob += math.log(p)\n",
    "\n",
    "    return math.exp(-log_prob / T)\n",
    "\n",
    "# =====================================================\n",
    "# MAIN\n",
    "# =====================================================\n",
    "\n",
    "def main():\n",
    "    print(\"Loading corpus...\")\n",
    "    tokens = load_tokens(CORPUS_PATH)\n",
    "\n",
    "    print(\"Total tokens:\", len(tokens))\n",
    "\n",
    "    train_tokens, test_tokens = split_data(tokens)\n",
    "\n",
    "    print(\"Train tokens:\", len(train_tokens))\n",
    "    print(\"Test tokens:\", len(test_tokens))\n",
    "\n",
    "    # Build models\n",
    "    unigram_counts, total = build_unigram(train_tokens)\n",
    "    bigram_counts = build_bigram(train_tokens)\n",
    "    trigram_counts = build_trigram(train_tokens)\n",
    "\n",
    "    # Compute perplexities\n",
    "    ppl_uni = perplexity_unigram(test_tokens, unigram_counts, total)\n",
    "    ppl_bi = perplexity_bigram(test_tokens, bigram_counts, unigram_counts)\n",
    "    ppl_tri = perplexity_trigram(test_tokens, trigram_counts, bigram_counts)\n",
    "\n",
    "    print(\"\\n=== Task 1 Results (No Smoothing) ===\")\n",
    "    print(\"Unigram Perplexity:\", ppl_uni)\n",
    "    print(\"Bigram Perplexity:\", ppl_bi)\n",
    "    print(\"Trigram Perplexity:\", ppl_tri)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
